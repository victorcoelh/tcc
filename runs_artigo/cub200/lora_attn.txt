Epochs: 60
Batch Size: 6
Optimizer: <class 'torch.optim.adam.Adam'>
Scheduler: <class 'torch.optim.lr_scheduler.OneCycleLR'>
Optimizer Config: {'lr': 0.0001, 'betas': (0.9, 0.985), 'eps': 1e-08, 'weight_decay': 0}
Scheduler Config: {'max_lr': 0.0001, 'epochs': 60, 'steps_per_epoch': 899, 'div_factor': 100}
