Epochs: 60
Batch Size: 6
Optimizer: <class 'torch.optim.adam.Adam'>
Scheduler: <class 'torch.optim.lr_scheduler.OneCycleLR'>
Optimizer Config: {'lr': 0.0001, 'betas': (0.9, 0.98), 'eps': 1e-06, 'weight_decay': 0.0001}
Scheduler Config: {'max_lr': 1e-05, 'epochs': 60, 'steps_per_epoch': 800, 'div_factor': 100}
