# Resultados no subset de teste

## Satellites
|                 |     Cider     |     Meteor    |   BertScore   |       Spice       | Trnble Params |
| :-------------: | :-----------: | :-----------: | :-----------: | :---------------: | :-----------: |
|     FineTune    | 0.65 +/- 0.62 | 0.47 +/- 0.22 | 0.50 +/- 0.18 | 0.2434 +/- 0.1336 |     100%      |
| *WiSE - Optimal | 0.62 +/- 0.55 | 0.43 +/- 0.20 | 0.48 +/- 0.14 | 0.2215 +/- 0.1281 |     100%      |
|    LayerNorm    | 0.69 +/- 0.59 | 0.48 +/- 0.23 | 0.51 +/- 0.16 | 0.2440 +/- 0.1320 |     0.03%     |
|   LoRA (Attn)   | 0.63 +/- 0.56 | 0.46 +/- 0.22 | 0.50 +/- 0.16 | 0.2294 +/- 0.1322 |     2.29%     |
|  LoRA (All Lin) | 0.68 +/- 0.60 | 0.48 +/- 0.23 | 0.51 +/- 0.17 | 0.2417 +/- 0.1347 |     4.04%     |
|   B. Adapters   | 0.68 +/- 0.65 | 0.49 +/- 0.23 | 0.51 +/- 0.19 | 0.2530 +/- 0.1364 |     2.46%     |

* -> Optimal alpha found to be 0.85

## CUB-200
|                 |     Cider     |     Meteor    |   BertScore   |       Spice       | Trnble Params |
| :-------------: | :-----------: | :-----------: | :-----------: | :---------------: | :-----------: |
|     FineTune    | 0.68 +/- 0.62 | 0.71 +/- 0.22 | 0.78 +/- 0.17 | 0.1712 +/- 0.0534 |     100%      |
| *WiSE - Optimal | 0.55 +/- 0.53 | 0.67 +/- 0.19 | 0.73 +/- 0.15 | 0.1772 +/- 0.0553 |     100%      |
|    LayerNorm    | 0.69 +/- 0.61 | 0.71 +/- 0.22 | 0.77 +/- 0.17 | 0.1757 +/- 0.0548 |     0.03%     |
|   LoRA (Attn)   | 0.68 +/- 0.60 | 0.70 +/- 0.21 | 0.75 +/- 0.16 | 0.1852 +/- 0.0581 |     2.29%     |
|  LoRA (All Lin) | 0.60 +/- 0.56 | 0.68 +/- 0.19 | 0.73 +/- 0.16 | 0.1838 +/- 0.0581 |     4.04%     |
|   B. Adapters   | 0.60 +/- 0.57 | 0.69 +/- 0.22 | 0.76 +/- 0.17 | 0.1687 +/- 0.0559 |     2.46%     |

* -> Optimal alpha found to be 0.90


# Resultados com Grid Search

## Satellites
|                 |     Cider     |     Meteor    |   BertScore   |       Spice       | Trnble Params |
| :-------------: | :-----------: | :-----------: | :-----------: | :---------------: | :-----------: |
|     FineTune    | 0.75 +/- 0.69 | 0.49 +/- 0.24 | 0.52 +/- 0.20 | 0.2502 +/- 0.1348 |     100%      | 0.67, 0.47, 0.49, 0.2451
| *WiSE - Optimal | 0.74 +/- 0.68 | 0.48 +/- 0.24 | 0.51 +/- 0.19 | 0.2460 +/- 0.1379 |     100%      |
|    LayerNorm    | 0.63 +/- 0.61 | 0.48 +/- 0.23 | 0.50 +/- 0.18 | 0.2395 +/- 0.1320 |     0.03%     | 0.63, 0.46, 0.50, 0.2280
|   LoRA (Attn)   | 0.75 +/- 0.64 | 0.50 +/- 0.23 | 0.52 +/- 0.18 | 0.2559 +/- 0.1342 |     2.29%     | 0.59, 0.45, 0.46, 0.2383
|  LoRA (All Lin) | 0.72 +/- 0.62 | 0.49 +/- 0.23 | 0.51 +/- 0.18 | 0.2530 +/- 0.1354 |     4.04%     | 0.70, 0.49, 0.51, 0.2534
|   B. Adapters   | 0.69 +/- 0.62 | 0.49 +/- 0.23 | 0.50 +/- 0.18 | 0.2580 +/- 0.1318 |     2.46%     | 0.63, 0.45, 0.48, 0.2381

* -> Optimal alpha found to be 0.85

## CUB-200
|                 |     Cider     |     Meteor    |   BertScore   |       Spice       | Trnble Params |
| :-------------: | :-----------: | :-----------: | :-----------: | :---------------: | :-----------: |
|     FineTune    | 0.71 +/- 0.61 | 0.71 +/- 0.21 | 0.76 +/- 0.17 | 0.1882 +/- 0.0580 |     100%      | 0.57, 0.66, 0.72, 0.1906
| *WiSE - Optimal | 0.61 +/- 0.55 | 0.68 +/- 0.19 | 0.73 +/- 0.15 | 0.1906 +/- 0.0608 |     100%      |
|    LayerNorm    | 0.69 +/- 0.61 | 0.71 +/- 0.22 | 0.77 +/- 0.17 | 0.1757 +/- 0.0548 |     0.03%     | 0.52, 0.66, 0.72, 0.1799
|   LoRA (Attn)   | 0.68 +/- 0.58 | 0.70 +/- 0.20 | 0.75 +/- 0.16 | 0.1875 +/- 0.0575 |     2.29%     | 0.40, 0.60, 0.67, 0.1676
|  LoRA (All Lin) | 0.73 +/- 0.62 | 0.71 +/- 0.21 | 0.77 +/- 0.17 | 0.1845 +/- 0.0570 |     4.04%     | 0.71, 0.71, 0.77, 0.1807
|   B. Adapters   | 0.75 +/- 0.65 | 0.73 +/- 0.23 | 0.79 +/- 0.18 | 0.1763 +/- 0.0543 |     2.46%     | 0.75, 0.73, 0.79, 0.1773

* -> Optimal alpha found to be 0.90
